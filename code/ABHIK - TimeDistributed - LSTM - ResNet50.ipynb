{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633b97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d54a3ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:56:04.305553: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 22:56:04.484950: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-24 22:56:05.291975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-11-24 22:56:05.292074: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-11-24 22:56:05.292083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07cdf77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "root_dir = './Data Files'    # CHANGE BASED ON FOLDER LOCATION\n",
    "sub_folder = 'short axis frames'\n",
    "dataframe_path = './Data Files/new_image_labels_gcp.csv'  # Update the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b2a7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3256 non-validated image filenames.\n",
      "Found 611 non-validated image filenames.\n",
      "Found 204 non-validated image filenames.\n"
     ]
    }
   ],
   "source": [
    " # Load DataFrames\n",
    "original_data = pd.DataFrame()\n",
    "for video_folder in os.listdir(os.path.join(root_dir, sub_folder)):\n",
    "    video_path = os.path.join(root_dir, sub_folder, video_folder)\n",
    "    if os.path.isdir(video_path):\n",
    "        label_file = os.path.join(root_dir, 'shortaxis_binary v2.xlsx')\n",
    "        try:\n",
    "            labels_df = pd.read_excel(label_file, sheet_name=video_folder)\n",
    "        except ValueError:\n",
    "            continue\n",
    "        \n",
    "        for img_filename in os.listdir(video_path):\n",
    "            if img_filename.endswith(\".jpg\"):\n",
    "                img_path = os.path.join(video_path, img_filename)\n",
    "                frame_idx = int(os.path.splitext(img_filename)[0].split('_')[-1])\n",
    "                labels = labels_df.loc[frame_idx, ['BAD QUALITY', 'CORD', 'FLUID']].values.astype('float32')\n",
    "                new_data = {\n",
    "                    'FILENAME': img_path,\n",
    "                    'BAD QUALITY': labels[0],\n",
    "                    'CORD': labels[1],\n",
    "                    'FLUID': labels[2]}\n",
    "                original_data = pd.concat([original_data, pd.DataFrame(new_data, index=[0])], axis=0)\n",
    "\n",
    "new_data = pd.read_csv(dataframe_path)\n",
    "\n",
    "# Combine datasets\n",
    "combined_data = pd.concat([original_data, new_data], ignore_index=True)\n",
    "\n",
    "# Split datasets\n",
    "train_data, temp_data = train_test_split(combined_data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.25, random_state=42)\n",
    "\n",
    "# Define ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale=1.0 / 255, rotation_range=15, zoom_range=0.2, horizontal_flip=True)\n",
    "val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Helper function to create generators\n",
    "def create_generator(datagen, dataframe, batch_size, target_size=(128, 128)):\n",
    "    return datagen.flow_from_dataframe(\n",
    "        dataframe,\n",
    "        x_col='FILENAME',\n",
    "        y_col=['BAD QUALITY', 'CORD', 'FLUID'],\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='raw',\n",
    "        shuffle=False,\n",
    "        validate_filenames = False\n",
    "    )\n",
    "\n",
    "# Create generators\n",
    "batch_size = 8\n",
    "train_generator = create_generator(train_datagen, train_data, batch_size)\n",
    "val_generator = create_generator(val_test_datagen, val_data, batch_size)\n",
    "test_generator = create_generator(val_test_datagen, test_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd149cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import ConvLSTM2D, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3036053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sequence_generator(data_generator, time_steps, batch_size):\n",
    "    \"\"\"\n",
    "    Transforms a data generator to output sequences for LSTM or TimeDistributed models.\n",
    "    \n",
    "    Args:\n",
    "    - data_generator: Original data generator (e.g., train_generator).\n",
    "    - time_steps: Number of frames in each sequence.\n",
    "    - batch_size: Number of sequences per batch.\n",
    "    \n",
    "    Returns:\n",
    "    - Generator yielding batches of sequences (batch_size, timesteps, height, width, channels) and labels.\n",
    "    \"\"\"\n",
    "    # Buffer to store frames and labels for creating sequences\n",
    "    frame_buffer = []\n",
    "    label_buffer = []\n",
    "\n",
    "    for batch_x, batch_y in data_generator:\n",
    "        # Append frames and labels to the buffers\n",
    "        for i in range(len(batch_x)):\n",
    "            frame_buffer.append(batch_x[i])\n",
    "            label_buffer.append(batch_y[i])\n",
    "\n",
    "            # When we have enough frames to form a sequence\n",
    "            if len(frame_buffer) >= time_steps:\n",
    "                # Form a sequence\n",
    "                sequence_x = np.array(frame_buffer[:time_steps])  # First `time_steps` frames\n",
    "                sequence_y = np.array(label_buffer[time_steps - 1])  # Label of the last frame\n",
    "\n",
    "                # Remove used frames and labels from the buffer\n",
    "                frame_buffer.pop(0)\n",
    "                label_buffer.pop(0)\n",
    "\n",
    "                # Yield a batch of sequences\n",
    "                yield (\n",
    "                    np.expand_dims(sequence_x, axis=0),  # Add batch dimension\n",
    "                    np.expand_dims(sequence_y, axis=0)   # Add batch dimension\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "516ea6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 10  # Define the number of frames per sequence\n",
    "\n",
    "# Create sequence generators for train and validation\n",
    "train_sequence_generator = create_sequence_generator(train_generator, time_steps, 16)\n",
    "val_sequence_generator = create_sequence_generator(val_generator, time_steps, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83dda751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:58:14.974626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.013358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.016898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.020580: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 22:58:15.022992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.026303: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.029377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.343478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.345609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.347515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-24 22:58:15.349410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13764 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "234698864/234698864 [==============================] - 8s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16, ResNet50, ResNet152\n",
    "from keras.layers import (\n",
    "    Input, Dense, Dropout, LSTM, TimeDistributed, GlobalAveragePooling2D, BatchNormalization\n",
    ")\n",
    "from keras.models import Model\n",
    "\n",
    "# Parameters\n",
    "image_height, image_width, no_of_channels = 128, 128, 3\n",
    "timesteps = 10\n",
    "no_of_classes = 3  # BAD QUALITY, CORD, FLUID\n",
    "\n",
    "# Load pre-trained VGG16\n",
    "ResNet_base = ResNet152(input_shape=(image_height, image_width, no_of_channels), \n",
    "                   weights=\"imagenet\", include_top=False)\n",
    "\n",
    "# Add global average pooling to get fixed-length feature vectors\n",
    "ResNet_output = GlobalAveragePooling2D()(ResNet_base.output)\n",
    "ResNet_model = Model(ResNet_base.input, ResNet_output)\n",
    "ResNet_model.trainable = True  # Freeze the VGG16 base\n",
    "\n",
    "# Input for video sequences\n",
    "video_input = Input(shape=(timesteps, image_height, image_width, no_of_channels))\n",
    "\n",
    "# Encode each frame using the VGG16 model (shared across frames)\n",
    "video_frames_encoded = TimeDistributed(ResNet_model)(video_input)\n",
    "\n",
    "# Process the encoded sequence using LSTM\n",
    "video_frames_encoded_sequence = LSTM(1024, return_sequences=False)(video_frames_encoded)\n",
    "video_frames_encoded_sequence = Dropout(0.25)(video_frames_encoded_sequence)\n",
    "\n",
    "# Fully connected layers with Dropout and Batch Normalization\n",
    "hidden_layer1 = Dense(1024, activation=\"relu\")(video_frames_encoded_sequence)\n",
    "hidden_layer1 = BatchNormalization()(hidden_layer1)\n",
    "hidden_layer1 = Dropout(0.2)(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = Dense(512, activation=\"relu\")(hidden_layer1)\n",
    "hidden_layer2 = BatchNormalization()(hidden_layer2)\n",
    "hidden_layer2 = Dropout(0.2)(hidden_layer2)\n",
    "\n",
    "hidden_layer3 = Dense(256, activation=\"relu\")(hidden_layer2)\n",
    "hidden_layer3 = BatchNormalization()(hidden_layer3)\n",
    "hidden_layer3 = Dropout(0.2)(hidden_layer3)\n",
    "\n",
    "hidden_layer4 = Dense(128, activation=\"relu\")(hidden_layer3)\n",
    "hidden_layer4 = BatchNormalization()(hidden_layer4)\n",
    "hidden_layer4 = Dropout(0.2)(hidden_layer4)\n",
    "\n",
    "hidden_layer5 = Dense(64, activation=\"relu\")(hidden_layer4)\n",
    "hidden_layer5 = BatchNormalization()(hidden_layer5)\n",
    "hidden_layer5 = Dropout(0.2)(hidden_layer5)\n",
    "\n",
    "# Output layer for multi-label classification\n",
    "outputs = Dense(no_of_classes, activation=\"sigmoid\")(hidden_layer5)\n",
    "\n",
    "# Define the model\n",
    "model = Model([video_input], outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90b0b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"binary_crossentropy\", \n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03c32f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 128, 128, 3)  0         \n",
      "                             ]                                   \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 10, 2048)         58370944  \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 1024)              12587008  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              1049600   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 1024)             4096      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,712,963\n",
      "Trainable params: 72,557,571\n",
      "Non-trainable params: 155,392\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a616323e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 22:59:09.999280: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 41s 302ms/step - loss: 0.6671 - accuracy: 0.6000 - val_loss: 0.6321 - val_accuracy: 0.4286\n",
      "Epoch 2/10\n",
      "40/40 [==============================] - 7s 174ms/step - loss: 0.5878 - accuracy: 0.6500 - val_loss: 0.4800 - val_accuracy: 0.7143\n",
      "Epoch 3/10\n",
      "40/40 [==============================] - 7s 175ms/step - loss: 0.5369 - accuracy: 0.5750 - val_loss: 0.7612 - val_accuracy: 0.1429\n",
      "Epoch 4/10\n",
      "40/40 [==============================] - 7s 175ms/step - loss: 0.5193 - accuracy: 0.5250 - val_loss: 1.6624 - val_accuracy: 0.1429\n",
      "Epoch 5/10\n",
      "40/40 [==============================] - 7s 176ms/step - loss: 0.4540 - accuracy: 0.6500 - val_loss: 5.5950 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "40/40 [==============================] - 7s 177ms/step - loss: 0.3880 - accuracy: 0.7250 - val_loss: 22.7617 - val_accuracy: 0.4286\n",
      "Epoch 7/10\n",
      "40/40 [==============================] - 7s 178ms/step - loss: 0.5154 - accuracy: 0.5000 - val_loss: 23.1754 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "40/40 [==============================] - 7s 178ms/step - loss: 0.6147 - accuracy: 0.5000 - val_loss: 101.9830 - val_accuracy: 0.5714\n",
      "Epoch 9/10\n",
      "40/40 [==============================] - 7s 179ms/step - loss: 0.5624 - accuracy: 0.4500 - val_loss: 67.0006 - val_accuracy: 0.8571\n",
      "Epoch 10/10\n",
      "40/40 [==============================] - 7s 179ms/step - loss: 0.5413 - accuracy: 0.5000 - val_loss: 512.5734 - val_accuracy: 0.7143\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff4901b6320>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_sequence_generator,\n",
    "    validation_data=val_sequence_generator,\n",
    "    epochs=10,\n",
    "    steps_per_epoch=len(train_generator) // time_steps,\n",
    "    validation_steps=len(val_generator) // time_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78e9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
